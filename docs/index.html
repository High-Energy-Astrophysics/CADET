<!DOCTYPE html>
<html lang="en">
<head>
<title>CADET</title>
<link rel="icon" href="figures/CADET.png">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>

<body>
<link rel="stylesheet" href="styles.css">
<!-- <link rel="stylesheet" href="prism.css"> -->

<a href="https://github.com/tomasplsek/CADET"><img src="figures/github.png" style="position: relative; width: 100px; left: 0%; top: 17px; float: right; margin-right: 0px;"></a>

<header><em>Cavity Detection Tool</em>  (CADET)</header>

<img src="figures/CADET.png" style="float: right; width: 290px; padding-right: 120px; position: fixed; left: 78%; top: 21%;">

<div class="sidenav">
<a style="color: rgb(20, 97, 179);font-weight: bold;" id="menu" href="index.html">Overview</a>
<a id="menu" href="training.html">Training</a>
<!-- <a id="menu" href="requirements.html">Requirements</a> -->
<a id="menu" href="usage.html">Usage</a>
<a id="menu" href="results.html">Results</a>
<!-- <a id="menu" href="example.html">Example</a> -->
<!-- <a id="menu" href="CADET.html">CADET</a> -->
</div>

<main>

<section>

<h1>Overview</h1>

    <p>
        <a href="https://tomasplsek.github.io/CADET/">CADET</a> is a machine learning pipeline trained for identification of 
        surface brightness depressions (so-called <em>X-ray cavities</em>) on noisy <em>Chandra</em> images of early-type 
        galaxies and galaxy clusters. The pipeline consists of a convolutional neural network trained for producing pixel-wise 
        cavity predictions and a DBSCAN clustering algorithm, which decomposes the predictions into individual cavities. 
        The pipeline is further described in <a targer="_blank" href="https://arxiv.org/abs/2304.05457">Plšek et al. 2023</a>.
    </p>

    <p>
        The architecture of the convolutional network consists of 5 convolutional blocks, each resembling an 
        nception layer, it was implemented using <em>Keras</em> library and it's development was inspired by 
        <a href="https://ui.adsabs.harvard.edu/abs/2017arXiv171200523F/abstract">Fort et al. 2017</a> and 
        <a href="https://is.muni.cz/th/rnxoz/?lang=en;fakulta=1411">Secká 2019</a>. For the clustering, 
        we utilized is the <em>Scikit-learn</em> implementation of the Density-Based Spatial Clustering of 
        Applications with Noise (DBSCAN, 
        <a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.121.9220">Ester et al. 1996</a>).
    </p>

<br>

<img src="figures/architecture.png" title="Architecture of the CADET pipeline" style="width: 100%;">

<br>

<h2>Network architecture</h2>

<p>

On the input of the CNN, there is a single channel 128x128 image. Since radial profiles of β-models in 
both real and simulated images are rather exponential, we transform the input images by a decimal 
logarithm (the value of each pixel was raised by one to avoid calculating the logarithm of zero).
Before the images are processed by the first Inception-like convolutional block, they are further 
normalized in mini-batches by a batch-normalization layer within the convolutional neural network.

<br class="longbr">

The architecture of the convolutional neural network is similar to that developed by Fort2017 and 
is composed of a series of 5 convolutional blocks. Each block resembles an Inception-like layer (Szegedy2015) 
as it applies a set of multiple parallel 2D convolutions with various kernel sizes and concatenates 
their outputs. Inception layers within the first 4 blocks consist of convolutional layers with 32 of 1x1 
filters, 32 of 3x3 filters, 16 of 5x5 filters, 8 of 7x7 filters, 4 of 9x9 filters, 2 of 11x11 filters, and one 13x13 filter. 
The output of each convolutional layer within the Inception-like layer is activated by Rectified Linear 
Unit (ReLU; Fukushima1975) activation function, which brings non-linear elements into the network, 
and then normalized by batch normalization (Ioffe2015). Each Inception layer is then followed by a 
2D convolutional layer with 32 or 64 of 1x1 filters, which is introduced mainly due to dimensionality reduction.
The output of this convolutional layer is also activated using the ReLU activation function and batch-normalized. 
The 1x1 convolutional layers are, in order to prevent overfitting, followed by a dropout layer, where 
the dropout rate was varied as a hyper-parameter.

<br class="longbr">

The convolutional neural network is ended by a final block, which is as well composed as an Inception-like 
layer but differs from the previous blocks by the numbers and sizes of individual 2D convolutional 
filters (8 of 8x8 filters, 4 of 16x16 filters, 2 of 32x32 filters, and one 64x64 filter) and also 
by the activation function of the last 1x1 convolutional filter. Since the output of the network is 
intended to be a prediction of whether a corresponding pixel belongs to a cavity (value 1) or not (value 0), 
the activation function of the final layer was set to be the <em>sigmoid</em> function, which 
outputs real numbers in the range between 0 and 1.

<br class="longbr">

In total, the network has 563 146 trainable parameters and the size of the model is 7.4 MB. Weights 
of individual 2D convolutional layers were generated using He initialization (He2015) and biases 
were initialized with low but non-zero values (0.01). 

<br class="longbr">

On the output of the CNN, there is a pixel-wise prediction of the same shape as the input image 
with a value in each pixel ranging from 0 to 1, which expresses whether that pixel corresponds to a cavity or not.
The pixel-wise prediction is then decomposed into individual X-ray cavities using the DBSCAN clustering 
algorithm. Before the decomposition, a pair of discrimination thresholds are applied for the pixel-wise 
prediction excluding low-significance regions and keeping only solid cavity predictions while properly 
estimating their areas and volumes.

</p>

<br>

<img src="figures/netron_full.png" title="Network architecture" style="width: 100%;">

<p style="font-size: 92%;">
  Figure: The schematic picture of the convolutional neural network composed of 5 Inception-like blocks. Each block 
  consists of a series of parallel convolutional layers each composed of various numbers of convolutional 
  filters with various sizes. The output of all parallel convolutional layers is then concatenated into a 
  single output, followed by a convolutional layer with 32 of 1x1 filters and a dropout layer, 
  which was for simplicity omitted. The scheme was created using the <a target="_blank" href="https://netron.app/">Netron</a> visualisation tool.
</p.>

<br class="longbr">

</section>

</main>

<footer>
    &#169; <a target="_blank" style="color:white;" href="https://www.physics.muni.cz/~plsek/index-EN.html">Tomáš Plšek</a> <span style="font-weight: bolder;">&middot;</span> July 2021
</footer>    

</body>

</html>